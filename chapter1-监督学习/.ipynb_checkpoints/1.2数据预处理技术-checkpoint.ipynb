{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入包后，创建一些样本数据\n",
    "data = np.array([[3,-1.5,2,-5.4],[0, 4, -0.3, 2.1],[1, 3.3, -1.9, -4.3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3. , -1.5,  2. , -5.4],\n",
       "       [ 0. ,  4. , -0.3,  2.1],\n",
       "       [ 1. ,  3.3, -1.9, -4.3]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 均值移除  \n",
    "把每个特征的平均值移除，保证特征均值为0（即标准化处理）。这样做可以消除特征之间的偏差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean = [ 5.55111512e-17 -1.11022302e-16 -7.40148683e-17 -7.40148683e-17]\n",
      "Std deviation = [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# 均值移除\n",
    "data_standardized = preprocessing.scale(data)\n",
    "print('Mean =',data_standardized.mean(axis=0))\n",
    "print('Std deviation =',data_standardized.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 范围缩放\n",
    "数据预处理中每个特征的范围变化很大，因此，将特征的数值范围缩放到合理的范围很重要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min max scaled data= [[1.         0.         1.         0.        ]\n",
      " [0.         1.         0.41025641 1.        ]\n",
      " [0.33333333 0.87272727 0.         0.14666667]]\n"
     ]
    }
   ],
   "source": [
    "data_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "data_scaled = data_scaler.fit_transform(data)\n",
    "print('Min max scaled data=',data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 归一化\n",
    "归一化用于需要对特征向量的值进行调整时，保证每个特征向量的值都缩放到相同的数值范围。  \n",
    "机器学习中最常用的归一化形式就是将特征向量调整为L1范数，使特征向量的数值之和为1\n",
    "\n",
    "这个方法经常用于确保数据点没有因为特征的基本性质而产生较大差异，即确保数据处于同一数量级，提高不同特征数据的可比性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L1 normalized data = [[ 0.25210084 -0.12605042  0.16806723 -0.45378151]\n",
      " [ 0.          0.625      -0.046875    0.328125  ]\n",
      " [ 0.0952381   0.31428571 -0.18095238 -0.40952381]]\n"
     ]
    }
   ],
   "source": [
    "data_normalized = preprocessing.normalize(data,norm='l1')\n",
    "print('\\nL1 normalized data =',data_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二值化\n",
    "二值化用于将数值特征向量转换为布尔类型向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarized data = [[1. 0. 1. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "data_binarized = preprocessing.Binarizer(threshold=1.4).transform(data)\n",
    "print('Binarized data =',data_binarized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 独热编码\n",
    "数据分布是稀疏的、散乱的分布在空间中，然而，并不需要存储这些大数值，需要使用独热编码（one-Hot encoding）。   \n",
    "把特征向量的每个特征都按照这个特征与特征的非重复总数相对应，通过one-of-k的形式对每个值进行编码。  \n",
    "理解就是一个特征向量第n个特征一共有多少不同的值，然后把特征转换为只有一个值为1，其他的值为0 ，长度就是特征的不同数值，长度会变长，但是都是0,1值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "encoder = preprocessing.OneHotEncoder()\n",
    "encoder.fit([[0,2,1,12],[1,3,5,3],[2,3,2,12],[1,2,4,3]])\n",
    "encoder_vector = encoder.transform([[2,3,5,3]]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder vector= [[0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoder vector=\",encoder_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
